# Assignment 7

+ OPTIONAL
+ Lab Saturday, December 3rd, 3-5 pm, McCabe Computer Classroom (third floor)
+ Estimated time: 2 hours

### Very Large Language Models

Recent years have seen a lot of dicussion about the [possibilites](https://tedunderwood.com/) and [dangers](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922) of large language models (LMs). LMs are a type of natural language processing (NLP) that "learn" from a large existing corpus of texts and then can be used to "predict" the likelihood of a token (for example, a letter or word) that will appear next (or in its context). In simple language, these models can be used to generate new text based on what they know about how the language in their training corpora behaves.

This assignment is not a fully developed exercise; instead, I would like you to [play with this lightweight version of a large language model](https://6b.eleuther.ai/?fbclid=IwAR1dK6PYMOPCkAEf5sQ99lkcs2q0Up_bcjN4kndpI99uV0UZkjtQ6L1sPf8) to see what you can do with it, and to ask when it seems good at generating text that is like the text you put in, and when it fails. Maybe try feeding some paragraphs of our novels from various centuries into it to see what happens, and reflect on that. What might these LMs teach us about fiction? How might they teach us new things about the history of the novel?

You might also read the blog post and article linked above, as well as seek out more information on these language models by yourselve, in order to then meditate (even tentatively) on what they might be good for and what their dangers might be.

This extra credit assignment is obviously open-ended; you might write a few paragraphs prompted by one of these questions, or do something more extensive. 
